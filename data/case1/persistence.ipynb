{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "# from utils import freq\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15907, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts = pd.read_csv('all_posts.csv',  encoding='utf-8', dtype={'user_id':str})\n",
    "# 把nan变为None\n",
    "# df_posts = df_posts.where(pd.notnull(df_posts), None)\n",
    "\n",
    "df_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照日期限制范围\n",
    "def get_post_date_range(df,start,end,cluster = None):\n",
    "    if cluster:\n",
    "        df_cluster = df[df['cluster'] == cluster]\n",
    "    else:\n",
    "        df_cluster = df\n",
    "    # end要加一天\n",
    "    end = pd.to_datetime(end) + pd.Timedelta(days=1)\n",
    "    df_date = df_cluster[(df_cluster['publish_time'] >= start) & (df_cluster['publish_time'] <= end)]\n",
    "    return df_date\n",
    "# 按照cluster统计每组的数量\n",
    "def get_post_gorup_count(df,group = 'cluster'):\n",
    "    df_cluster_count = df.groupby(group).size().reset_index(name='count')\n",
    "    return df_cluster_count\n",
    "get_post_gorup_count(df_posts)\n",
    "# 根据文本列表查找\n",
    "def get_post_by_text_list(df,text_list):\n",
    "    df_text = df[df['text'].str.contains('|'.join(text_list))]\n",
    "    return df_text\n",
    "# 把df_snccll的时间随机到'2021-04-20','2021-04-29'，注意要带上时分秒\n",
    "def random_date(df,start,end):\n",
    "    df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['publish_time'] = df['publish_time'].apply(lambda x: x.replace(year=2021, month=4, day=np.random.randint(20, 30)))\n",
    "    df['publish_time'] = df['publish_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return df\n",
    "def get_post_date_range(df,start,end,cluster = None):\n",
    "    if cluster:\n",
    "        df_cluster = df[df['cluster'] == cluster]\n",
    "    else:\n",
    "        df_cluster = df\n",
    "    df_date = df_cluster[(df_cluster['publish_time'] >= start) & (df_cluster['publish_time'] <= end)]\n",
    "    return df_date\n",
    "# 按照日期限制范围\n",
    "def get_post_date_out_range(df,start,end,cluster = None):\n",
    "    if cluster:\n",
    "        df_cluster = df[df['cluster'] == cluster]\n",
    "    else:\n",
    "        df_cluster = df\n",
    "    df_date = df_cluster[(df_cluster['publish_time'] < start) | (df_cluster['publish_time'] > end)]\n",
    "    return df_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# japan_dead_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 19)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts[df_posts['cluster'] =='japan_dead_fish'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 19)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找 2023.12.1 -> 2023.12.10之间，twitter上query为japan dead fish的\n",
    "df_data_twitter = df_posts[df_posts['from'] == 'twitter']\n",
    "df_data_twitter = get_post_date_range(df_data_twitter,'2023-12-01','2023-12-10')\n",
    "df_data_twitter = df_data_twitter[df_data_twitter['query']== \"Japan dead fish\"]\n",
    "df_data_twitter.shape\n",
    "# 把这些data的cluster设置为japan_dead_fish\n",
    "df_data_twitter['cluster'] = 'japan_dead_fish'\n",
    "# 更新这些数据在df_posts\n",
    "df_posts.update(df_data_twitter)\n",
    "df_posts[df_posts['cluster'] =='japan_dead_fish'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 19)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_weibo = df_posts[df_posts['from'] == 'weibo']\n",
    "df_data_weibo = get_post_date_range(df_data_weibo,'2023-12-01','2023-12-10')\n",
    "df_data_weibo = df_data_weibo[df_data_weibo['query'] == \"w9\"]\n",
    "df_data_weibo.shape\n",
    "# 把这些data的cluster设置为japan_dead_fish\n",
    "df_data_weibo['cluster'] = 'japan_dead_fish'\n",
    "# 更新这些数据在df_posts\n",
    "df_posts.update(df_data_weibo)\n",
    "df_posts[df_posts['cluster'] =='japan_dead_fish'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 19)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts[df_posts['cluster'] =='japan_dead_fish'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\n",
    "    1:('Great_Wave_Kanagawa', \"2021-04-20\", \"2021-04-29\"),\n",
    "    2:('foreign_affairs_questions', '2021-04-20', '2021-04-29'),\n",
    "    3:('japan_nuclear_wastewater', '2021-04-20', '2021-04-29'),\n",
    "    4:('radioactive_condemn_water', '2021-04-20', '2021-04-29'),\n",
    "    5:('240_china_nuclear_pollution', '2023-08-21', '2023-08-30'),\n",
    "    6:('70_billion_japan_water', '2023-08-21', '2023-08-30'),\n",
    "    7:('cooling_water_nuclear_wastewater', '2023-08-21', '2023-08-30'),\n",
    "    8:('south_korea_nuclear_discharge', '2023-08-21', '2023-09-01'),\n",
    "    9:('sue_TEPCO_japan', '2023-08-21', '2023-08-30'),\n",
    "    10:('radioactive_pollution_japan_sea', '2023-08-21', '2023-08-30'),\n",
    "    11:('treatment_japan_waste_nuclear', '2023-08-21', '2023-08-30'),\n",
    "    12: ('japan_dead_fish', '2023-12-01', '2023-12-10'),\n",
    "    13: ('border_...', '2023-12-21', '2024-03-25')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## border_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.loc[df_posts['query'].isin([\n",
    "    'shut down border', 'biden visits border', 'support of Texas', 'building a wall america', 'U.S.-Mexico border','US-Mexico border','trump visits border','e6','e9','']), 'cluster'] = \"border_...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossplatform",
   "language": "python",
   "name": "crossplatform"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
